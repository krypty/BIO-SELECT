{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIO-SELECT - Marigliano\n",
    "## Global pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_TODO_ : insert global pipeline image here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import neighbors, datasets\n",
    "import pandas as pd\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.multiclass import OneVsOneClassifier, OneVsRestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# set float precision at 2 digits\n",
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N_FEATURES_ALGORITHM = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset loading\n",
    "_TODO_: \n",
    "* this notebook must only load one dataset\n",
    "* retrieve dataset to load from cmd arguments or from env variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datasets.EGEOD22619.EGEOD22619Dataset import EGEOD22619Dataset\n",
    "from datasets.MILE.MileDataset import MileDataset\n",
    "from datasets.Golub99.GolubDataset import GolubDataset\n",
    "\n",
    "from datasets.DatasetEncoder import DatasetEncoder\n",
    "from datasets.DatasetSplitter import DatasetSplitter\n",
    "\n",
    "#ds = MileDataset()\n",
    "#ds = EGEOD22619Dataset()\n",
    "ds = GolubDataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset transformation\n",
    "The dataset needs some transformations such as encoding the outputs as float (necessary for scikit learn), normalization, ...\n",
    "\n",
    "_TODO_:\n",
    "* dataset splitting (train, test[, validation])\n",
    "* encode outputs\n",
    "* normalization\n",
    "* classes merging\n",
    "    * due to the low class balancing we might want to regroup them. Example Healthy vs Non-Healthy (choose the most represented class ?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# encode Dataset string classes into numbers\n",
    "ds_encoder = DatasetEncoder(ds)\n",
    "ds = ds_encoder.encode()\n",
    "ds = DatasetSplitter(ds, test_size=0.4)\n",
    "\n",
    "X = ds.get_X()\n",
    "y = ds.get_y()\n",
    "print(len(y))\n",
    "\n",
    "X_train = ds.get_X_train()\n",
    "y_train = ds.get_y_train()\n",
    "X_test = ds.get_X_test()\n",
    "y_test = ds.get_y_test()\n",
    "\n",
    "print(len(X_train[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithms\n",
    "Run the chosen algorithms and save them and their output subset of features using cPickle into files. They can be used later to display some graphs and to be analyzed\n",
    "\n",
    "_TODO_: Write a subsection for each algorithm :\n",
    "* OneVsRest or OneVsOne ?\n",
    "    * only for those who needs it\n",
    "* Grid search + CV\n",
    "    * maybe not for all algorithms such as SVM RFE which takes a lot of time\n",
    "    * not for algorthms which does not have parameters to tune (ReliefF, Fisher Score,...)\n",
    "* print classification report (accuracy, recall, precision, ...)\n",
    "    * issue: not all algortihms are able to do this\n",
    "* normalize score using minmax normalization (0-1)\n",
    "* show score per features (50 to 100 first ones)\n",
    "* save algorithm in a file\n",
    "\n",
    "Algorithms:\n",
    "* ExtraTrees\n",
    "* Random Forest\n",
    "* SVM\n",
    "* SVM RFE\n",
    "* ANN\n",
    "* ReliefF\n",
    "* Fisher Score\n",
    "* \"Best features subset ~ SVM\"\n",
    "* SVM Backward ?\n",
    "* CFS - Correlation-based Feature Selection\n",
    "* Mutual Information Classifier\n",
    "* One genetic based algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from algorithms.ExtraTreesAlgorithm import ExtraTreesAlgorithm\n",
    "\n",
    "eta = ExtraTreesAlgorithm(ds)\n",
    "\n",
    "feats_by_score = eta.get_best_features_by_score(n=N_FEATURES_ALGORITHM)\n",
    "print(feats_by_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features subsets merging\n",
    "Each algorithm has done its work and provided a subset of features as:\n",
    "* a ranked score list\n",
    "* a ranked list (no score)\n",
    "* a list (no ranking, no score)\n",
    "\n",
    "This part uses some techniques to combine/merge theses lists into a better one\n",
    "\n",
    "_TODO_: \n",
    "* implement merge techniques\n",
    "    * votation\n",
    "    * weighted votation\n",
    "    * union of intersection\n",
    "    * ...\n",
    "* Visualize the lists\n",
    "    * Venn diagram ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of the merged subset\n",
    "Once we have a merged list containing the best features, we would like to evaluate it with several classifiers\n",
    "\n",
    "_TODO_: use a separate test set ? -> split again train/test set -> no changes in the Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
