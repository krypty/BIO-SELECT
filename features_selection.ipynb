{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# BIO-SELECT - Marigliano\n",
    "## Global pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_TODO_ : insert global pipeline image here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import neighbors, datasets\n",
    "import pandas as pd\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.multiclass import OneVsOneClassifier, OneVsRestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from utils.ConfusionMatrix import ConfusionMatrix\n",
    "\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import math\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# set float precision at 2 digits\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# set the random seed for reproducibility\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N_FEATURES_ALGORITHM = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset loading\n",
    "_TODO_: \n",
    "* this notebook must only load one dataset\n",
    "* retrieve dataset to load from cmd arguments or from env variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datasets.EGEOD22619.EGEOD22619Dataset import EGEOD22619Dataset\n",
    "from datasets.MILE.MileDataset import MileDataset\n",
    "from datasets.Golub99.GolubDataset import GolubDataset\n",
    "\n",
    "from datasets.DatasetEncoder import DatasetEncoder\n",
    "from datasets.DatasetSplitter import DatasetSplitter\n",
    "from datasets.DatasetLoader import DatasetLoader\n",
    "from datasets.DatasetBalancer import DatasetBalancer\n",
    "\n",
    "# Load dataset from environment variable. This is used by automated scripts\n",
    "ds_class = DatasetLoader.load_from_env_var(default_dataset=\"Golub\")\n",
    "\n",
    "print(\"Dataset used: %s\" % ds_class.__name__)\n",
    "\n",
    "ds = ds_class()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset transformation\n",
    "The dataset needs some transformations such as encoding the outputs as float (necessary for scikit learn), normalization, ...\n",
    "\n",
    "_TODO_:\n",
    "* dataset splitting (train, test[, validation])\n",
    "* encode outputs\n",
    "* normalization\n",
    "* classes merging\n",
    "    * due to the low class balancing we might want to regroup them. Example Healthy vs Non-Healthy (choose the most represented class ?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# encode Dataset string classes into numbers\n",
    "ds_encoder = DatasetEncoder(ds)\n",
    "ds = ds_encoder.encode()\n",
    "\n",
    "ds_balancer = DatasetBalancer(ds)\n",
    "ds = ds_balancer.balance()\n",
    "\n",
    "ds = DatasetSplitter(ds, test_size=0.4)\n",
    "\n",
    "X = ds.get_X()\n",
    "y = ds.get_y()\n",
    "\n",
    "X_train = ds.get_X_train()\n",
    "y_train = ds.get_y_train()\n",
    "X_test = ds.get_X_test()\n",
    "y_test = ds.get_y_test()\n",
    "\n",
    "class_names = range(len(set(ds.get_y())))\n",
    "\n",
    "print(\"Number of genes: %d\" % len(X_train[0]))\n",
    "print(\"Dataset samples: %d\" % len(y))\n",
    "print(\"Train set size %d\" % len(X_train))\n",
    "print(\"Test set size %d\" % len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithms\n",
    "Run the chosen algorithms and save them and their output subset of features using cPickle into files. They can be used later to display some graphs and to be analyzed\n",
    "\n",
    "_TODO_: Write a subsection for each algorithm :\n",
    "* OneVsRest or OneVsOne ?\n",
    "    * only for those who needs it\n",
    "* Grid search + CV\n",
    "    * maybe not for all algorithms such as SVM RFE which takes a lot of time\n",
    "    * not for algorthms which does not have parameters to tune (ReliefF, Fisher Score,...)\n",
    "* print classification report (accuracy, recall, precision, ...)\n",
    "    * issue: not all algortihms are able to do this\n",
    "* normalize score using minmax normalization (0-1)\n",
    "* show score per features (50 to 100 first ones)\n",
    "* save algorithm in a file\n",
    "\n",
    "Algorithms:\n",
    "* ExtraTrees\n",
    "* Random Forest\n",
    "* SVM\n",
    "* SVM RFE\n",
    "* ANN\n",
    "* ReliefF\n",
    "* Fisher Score\n",
    "* \"Best features subset ~ SVM\"\n",
    "* SVM Backward ?\n",
    "* CFS - Correlation-based Feature Selection\n",
    "* Mutual Information Classifier\n",
    "* One genetic based algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from algorithms.Algorithm import NotSupportedException\n",
    "from algorithms.ExtraTreesAlgorithm import ExtraTreesAlgorithm\n",
    "from algorithms.ReliefFAlgorithm import ReliefFAlgorithm\n",
    "from algorithms.FisherScoreAlgorithm import FisherScoreAlgorithm\n",
    "from algorithms.FValueAlgorithm import FValueAlgorithm\n",
    "from algorithms.SVMAlgorithm import SVMAlgorithm\n",
    "from algorithms.GAANNAlgorithm import GAANNAlgorithm\n",
    "from algorithms.GridSearchableAlgorithm import GridSearchableAlgorithm\n",
    "from algorithms.SVMForwardAlgorithm import SVMForwardAlgorithm\n",
    "from algorithms.CFSAlgorithm import CFSAlgorithm\n",
    "from algorithms.MRMRAlgorithm import MRMRAlgorithm\n",
    "\n",
    "# the main idea here is to prepare all the algorithms in a list of tuple.\n",
    "# Then in a loop each algorithm will be runned and directly freed from memory\n",
    "# The goal is to keep the algorithm as less time as possible in memory\n",
    "algorithms = []\n",
    "\n",
    "\n",
    "# ExtraTrees\n",
    "eta_grid = [{\n",
    "        'n_estimators': np.arange(10, 1000, 300), \n",
    "        'criterion': [\"gini\", \"entropy\"], \n",
    "        'max_features': [\"sqrt\", \"auto\", \"log2\"],\n",
    "        'n_jobs': [2]\n",
    "    }]\n",
    "\n",
    "eta = (ExtraTreesAlgorithm, {\n",
    "        \"dataset\": ds,\n",
    "        \"n\": N_FEATURES_ALGORITHM,\n",
    "        \"gridsearch_params\": eta_grid\n",
    "    })\n",
    "algorithms.append(eta)\n",
    "\n",
    "\n",
    "# ReliefF\n",
    "rff = (ReliefFAlgorithm, {\n",
    "        \"dataset\": ds,\n",
    "        \"n\": N_FEATURES_ALGORITHM\n",
    "    })\n",
    "algorithms.append(rff)\n",
    "\n",
    "\n",
    "# Fisher score\n",
    "fsa = (FisherScoreAlgorithm, {\n",
    "        \"dataset\": ds,\n",
    "        \"n\": N_FEATURES_ALGORITHM\n",
    "    })\n",
    "algorithms.append(fsa)\n",
    "\n",
    "\n",
    "# F-Value\n",
    "fva = (FValueAlgorithm, {\n",
    "        \"dataset\": ds,\n",
    "        \"n\": N_FEATURES_ALGORITHM\n",
    "    })\n",
    "algorithms.append(fva)\n",
    "\n",
    "\n",
    "# SVM\n",
    "#FIXME: grid search for SVM always returns the first set of parameters, like all params give the same performance\n",
    "svm_grid_params = [{\n",
    "        'kernel':['linear'],\n",
    "        'C':[200, 0.1, 1, 10, 100, 1000],\n",
    "        'gamma' : [1e-2, 1e-3, 1e-4, 1e-5],\n",
    "        'tol' : [1e-2, 1e-3, 1e-4, 1e-5],\n",
    "        'cache_size':[1024],\n",
    "        'n_jobs': [2]\n",
    "    }]\n",
    "#%time svm_gs = SVMAlgorithm(ds, N_FEATURES_ALGORITHM, svm_grid_params)\n",
    "#algorithms.append(svm_gs)\n",
    "#print(\"Best params \\n\\t%s\" % svm_gs.best_params)\n",
    "\n",
    "\n",
    "svm = (SVMAlgorithm, {\n",
    "        \"dataset\": ds,\n",
    "        \"n\": N_FEATURES_ALGORITHM\n",
    "    })\n",
    "algorithms.append(svm)\n",
    "\n",
    "\n",
    "# GA ANN\n",
    "#%time gaanna = GAANNAlgorithm(ds, N_FEATURES_ALGORITHM)\n",
    "#algorithms.append(gaanna)\n",
    "\n",
    "\n",
    "# SVM Forward\n",
    "svm_forward = (SVMForwardAlgorithm, {\n",
    "        \"dataset\": ds,\n",
    "        \"n\" : N_FEATURES_ALGORITHM\n",
    "    })\n",
    "algorithms.append(svm_forward)\n",
    "\n",
    "\n",
    "# CFS\n",
    "cfs = (CFSAlgorithm, {\n",
    "        \"dataset\": ds,\n",
    "        \"n\": None # CFS gives its list\n",
    "    })\n",
    "algorithms.append(cfs)\n",
    "\n",
    "\n",
    "# MRMR\n",
    "mrmr = (MRMRAlgorithm, {\n",
    "        \"dataset\": ds,\n",
    "        \"n\": N_FEATURES_ALGORITHM\n",
    "    })\n",
    "algorithms.append(mrmr)\n",
    "\n",
    "\n",
    "subsets = []\n",
    "alg_names = []\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# the number of subplot is defined by the number of algorithm whose are able to provide a confusion matrix\n",
    "n_subplots = len([_ for a in algorithms if isinstance(a, GridSearchableAlgorithm)])\n",
    "cols = 3\n",
    "rows = max(1, int(math.ceil(n_subplots / cols)))\n",
    "i = 1\n",
    "\n",
    "for alg in algorithms:\n",
    "    alg_class = alg[0]\n",
    "    alg_kwargs = alg[1]\n",
    "    \n",
    "    print(\"Running %s...\" % alg_class.__name__)\n",
    "    \n",
    "    # instanciate and run the algorithm\n",
    "    alg_instance = alg_class(**alg_kwargs)\n",
    "    \n",
    "    feats = alg_instance.get_best_features()\n",
    "    \n",
    "    subsets.append(feats)\n",
    "    alg_names.append(alg_instance.name)\n",
    "    \n",
    "    try:\n",
    "        print(\"[%s] score: %.3f\" % (alg_instance.name, alg_instance.get_score()))\n",
    "    except NotSupportedException:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        cm = alg_instance.get_confusion_matrix()\n",
    "        plt.subplot(rows, cols, i)\n",
    "        ConfusionMatrix.plot(cm, class_names, title=\"Confusion matrix [%s]\" % alg_instance.name)\n",
    "        i += 1\n",
    "    except AttributeError:\n",
    "        pass\n",
    "    \n",
    "    # the algorithm is freed at the end of the loop, but the lists are kept\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TODO: run limma Rscript in bash, then read/parse the csv and add the features to `algorithms` object\n",
    "#TODO: convert feature names -> id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the features lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TODO save the features lists as a CSV file\n",
    "# format\n",
    "#alg_name,score,feat0,feat1,featN\n",
    "\n",
    "#TODO: pickle `algorithms` object in order to use it in the merging features notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features subsets merging\n",
    "Each algorithm has done its work and provide a subset of features as:\n",
    "* a ranked score list\n",
    "* a ranked list (no score)\n",
    "* a list (no ranking, no score)\n",
    "\n",
    "This part uses some techniques to combine/merge theses lists into a better one\n",
    "\n",
    "_TODO_: \n",
    "* Visualize the lists\n",
    "    * Venn diagram ? --> limited to 3 sets, does not scale\n",
    "    * matrix: show the similarity of features between two subsets\n",
    "        * Jaccard\n",
    "        * Union\n",
    "        * Cosine similarity\n",
    "* implement merge techniques\n",
    "    * votation\n",
    "    * weighted votation\n",
    "    * union of intersection\n",
    "    * ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subsets visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "\n",
    "# some set similarity functions\n",
    "def intersection_count(a, b):\n",
    "    return len(a.intersection(b))\n",
    "\n",
    "def jaccard(a, b):\n",
    "    return len(a.intersection(b))/float(len(a.union(b)))\n",
    "\n",
    "def compute_similary_between_subsets(subsets, compare_func):\n",
    "    N_subsets = len(subsets)\n",
    "    similarity_matrix = np.zeros(shape=(N_subsets, N_subsets))\n",
    "\n",
    "    for i, j in itertools.product(range(N_subsets), range(N_subsets)):\n",
    "        if isinstance(subsets[0][0], int):\n",
    "            subset_i = set(subsets[i])\n",
    "            subset_j = set(subsets[j])\n",
    "        else:\n",
    "            subset_i = {i[0] for i in subsets[i]}\n",
    "            subset_j = {j[0] for j in subsets[j]}\n",
    "\n",
    "        similarity_matrix[i, j] = compare_func(subset_i, subset_j)\n",
    "        \n",
    "    return similarity_matrix\n",
    "\n",
    "def plot_feature_subsets_matrix(cm, alg_names, title, cmap=plt.cm.Blues):\n",
    "    title += \"\\n\" # add a little margin for the title\n",
    "    \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    #plt.colorbar()\n",
    "    plt.title(title)\n",
    "    tick_marks = np.arange(len(alg_names))\n",
    "    plt.xticks(tick_marks, alg_names, rotation=45)\n",
    "    plt.yticks(tick_marks, alg_names)\n",
    "\n",
    "    thresh = cm.max() / 2.0 + 0.1\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        text = \"%.2f\" % cm[i, j]\n",
    "        plt.text(j, i, text,\n",
    "                 horizontalalignment=\"center\",\n",
    "                 backgroundcolor=\"white\",\n",
    "                 #color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "                 color=\"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "similarity_matrix = compute_similary_between_subsets(subsets, compare_func=jaccard)\n",
    "plt.figure(figsize=(6, 8))\n",
    "plot_feature_subsets_matrix(similarity_matrix, alg_names, title=\"Jaccard similarity between two feature subsets\")\n",
    "\n",
    "similarity_matrix = compute_similary_between_subsets(subsets, compare_func=intersection_count)\n",
    "plt.figure(figsize=(6, 8))\n",
    "plot_feature_subsets_matrix(similarity_matrix, alg_names, title=\"Intersection between two feature subsets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subsets merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from merge.simple.SimpleUnionSubsetMerger import SimpleUnionSubsetMerger\n",
    "\n",
    "susm = SimpleUnionSubsetMerger(subsets)\n",
    "merged_features = susm.merge()\n",
    "n_all_features = sum([len(s) for s in subsets])\n",
    "\n",
    "print(\"Unique features (union of all subsets): %d over a total of %d \" % (len(merged_features), n_all_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of the merged subset\n",
    "Once we have a merged list containing the best features, we would like to evaluate it with several classifiers\n",
    "\n",
    "_TODO_: use a separate test set ? -> split again train/test set -> no changes in the Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "is_list_unique = len(merged_features) == len(set(merged_features))\n",
    "print(\"is list unique\", is_list_unique)\n",
    "\n",
    "merged_features = list(merged_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "def assess_merged_features(clf, clf_name, assessment_scores):\n",
    "    clf.fit(ds.get_X_train(), ds.get_y_train())\n",
    "    y_pred = clf.predict(ds.get_X_test())\n",
    "    y_test = ds.get_y_test()\n",
    "\n",
    "    scores = cross_val_score(clf, ds.get_X_test()[:, merged_features], ds.get_y_test(), cv=3, n_jobs=-1)\n",
    "    score = np.mean(scores)\n",
    "\n",
    "    print(\"[%s] Score using the merged list of features: %.3f\" % (clf_name, score))\n",
    "\n",
    "    assessment_scores[clf_name] = score, (y_test, y_pred)\n",
    "\n",
    "    \n",
    "assessment_scores  = {}\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=5)\n",
    "assess_merged_features(clf, \"KNN\", assessment_scores)\n",
    "\n",
    "clf = MLPClassifier(solver=\"adam\", alpha=1e-3, hidden_layer_sizes=(100, 50), activation=\"relu\")\n",
    "#clf = MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', early_stopping=False,\n",
    "#       epsilon=1e-08, hidden_layer_sizes=(100,50), learning_rate='constant',\n",
    "#       learning_rate_init=0.001, max_iter=1000, momentum=0.9,\n",
    "#       nesterovs_momentum=True, power_t=0.5, shuffle=True,\n",
    "#       solver='lbfgs', tol=0.0001, verbose=False,\n",
    "#       warm_start=False)\n",
    "\n",
    "assess_merged_features(clf, \"MLP\", assessment_scores)\n",
    "\n",
    "clf = ExtraTreesClassifier(n_jobs=-1, n_estimators=100)\n",
    "assess_merged_features(clf, \"ExtraTrees\", assessment_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import math\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "n_subplots = len(assessment_scores)\n",
    "cols = 3\n",
    "rows = int(math.ceil(n_subplots / cols))\n",
    "i = 1\n",
    "\n",
    "for name, score_cm in assessment_scores.iteritems():\n",
    "    y_test, y_pred = score_cm[1]\n",
    "    cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    plt.subplot(rows, cols, i)\n",
    "    i += 1\n",
    "\n",
    "    ConfusionMatrix.plot(cnf_matrix, classes=class_names,\n",
    "                          title='Confusion matrix for %s' % name)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
