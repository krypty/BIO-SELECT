{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# GAANN - Genetic Algorithm and Artificial Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook tries to explain the details behind the implemented GAANN algorithm with an example.\n",
    "\n",
    "All the details are readable in the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The basic idea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GAANN is the combinaison of a [genetic algorithm](https://en.wikipedia.org/wiki/Genetic_algorithm) and an [artificial neural network](https://en.wikipedia.org/wiki/Multilayer_perceptron). It is a wrapper method since the output of the ANN, the score, is used to improve the classifier. As all the algorithms in this project, the classifier's score itself is not important but the features that give the best score are and the score is therefore used as an indicator.\n",
    "\n",
    "Let's see how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def timeit(method):\n",
    "    \"\"\"\n",
    "    Just a simple method to mesure the execution time of a method\n",
    "    \"\"\"\n",
    "    import time\n",
    "\n",
    "    def timed(*args, **kw):\n",
    "        ts = time.time()\n",
    "        result = method(*args, **kw)\n",
    "        te = time.time()\n",
    "\n",
    "        print('%r %2.2f sec' % (method.__name__, te - ts))\n",
    "        return result\n",
    "\n",
    "    return timed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The used score function is F1-Score. This function can leads to 0/0 division.\n",
    "# Theses following lines hide warnings about 0/0 divisions when computing the F-Score. \n",
    "# When looking at the source code, all 0/0 divisions are set to 0. \n",
    "import warnings\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# increase font size in matplotlib\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({'font.size': 12})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from datasets.DatasetEncoder import DatasetEncoder\n",
    "from datasets.DatasetSplitter import DatasetSplitter\n",
    "from datasets.Golub99.GolubDataset import GolubDataset\n",
    "from datasets.DatasetLoader import DatasetLoader\n",
    "from datasets.DatasetBalancer import DatasetBalancer\n",
    "\n",
    "from algorithms.GAANNAlgorithm import GAANNAlgorithm\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Load dataset from environment variable. This is used by automated scripts\n",
    "ds_class = DatasetLoader.load_from_env_var(default_dataset=\"MILE\")\n",
    "\n",
    "print(\"Dataset used: %s\" % ds_class.__name__)\n",
    "\n",
    "ds = ds_class()\n",
    "\n",
    "# encode Dataset string classes into numbers\n",
    "ds_encoder = DatasetEncoder(ds)\n",
    "ds = ds_encoder.encode()\n",
    "ds = DatasetSplitter(ds, test_size=0.4)\n",
    "\n",
    "ds_balancer = DatasetBalancer(ds)\n",
    "ds = ds_balancer.balance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# with verbose=True, we can see what are the slowest methods.\n",
    "N_FEATURES_TO_KEEP = 300\n",
    "gaanaa = GAANNAlgorithm(ds, N_FEATURES_TO_KEEP, verbose=True)\n",
    "\n",
    "# accessing to a private member is generally not a good idea, but see: https://mail.python.org/pipermail/tutor/2003-October/025932.html\n",
    "ga = gaanaa._ga"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The selection method is used to select the individuals for the next generation. The used method is fitness proportionate selection (https://en.wikipedia.org/wiki/Fitness_proportionate_selection)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crossover method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The crossover method is about combining two individuals, called male and female in the code, to create an other individual, called child in the code.\n",
    "\n",
    "The child creation consists of theses steps:\n",
    "1. take the features shared by both parents\n",
    "2. fill the remaining feature space using random unique features from the parents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mutation method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The mutation methods consists in attributing random unique features to a child. The mutation rate is fixed to 0.05."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keep the elite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure that the best individuals are not lost at the next generation, they are kept before doing any genetic operations. At the moment only the best individual is kept but this is tunable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitness method (ANN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fitness methods is a MLP which performs on all the dataset with a crossvalidation method (3 times). The mean of the runs is taken as the fitness score. The higher the score is the better the individual is. The crossvalidation allows to stabilize the score. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Population score evolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph below shows the evolution of the population score at each generation. The population score is computed using the 75th percentile of the individuals score. This is allow us to know that that at least 75% of the individuals (lists) in the population has a score equals or greater than the printed score. The individual score is based on F1 weigthed score method. This avoid the algorithm to focus on absolute accuracy which can be misleading in case of unbalanced dataset. See: http://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score\n",
    "\n",
    "In a previous implementation, only the very best individual was shown at each generation using bigger lists (1000 features). With the current implementation (100 features and 75th percentile) nearly all the generated lists are good enough and can be combined to build a bigger list (for example 1000 like the previous implementation)\n",
    "\n",
    "This algorithms works well with the Golub dataset since it shows that the score is increasing but using MILE dataset the score evolution is flat. Thus, the algorithm is working but it is not very helping in the case of MILE because the same score can be achieved with a random list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = ga._score_history\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(scores)\n",
    "plt.title(\"Evolution of the score \\n75th percentile score of the population at each generation\")\n",
    "plt.ylim(0, 1.1)\n",
    "plt.xlabel(\"Generations\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above, the evolution of the score does not increase as much as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The best list obtained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_f = max(ga._fitness_history, key=lambda x:x[1])\n",
    "print(\"Best score (%.2f) with this list of features by GAANN \\n%s\" % (best_f[1], best_f[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evolution of the similarity between the best list at each generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following graph shows the evolution of the similarity between the best list at generation N and the best list at generation N+1.\n",
    "\n",
    "With this graph, it shows that the algorithm seems to work because the lists are getting similar. Sometimes, there is a peak at y=1.0, this happens when the best lists at generation N and N+1 are exactly the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from itertools import islice, izip_longest\n",
    "\n",
    "def window(seq, n=2):\n",
    "    \"Returns a sliding window (of width n) over data from the iterable\"\n",
    "    \"   s -> (s0,s1,...s[n-1]), (s1,s2,...,sn), ...                   \"\n",
    "    it = iter(seq)\n",
    "    result = tuple(islice(it, n))\n",
    "    if len(result) == n:\n",
    "        yield result    \n",
    "    for elem in it:\n",
    "        result = result[1:] + (elem,)\n",
    "        yield result\n",
    "\n",
    "def jaccard(a, b):\n",
    "    return len(a.intersection(b))/float(len(a.union(b)))\n",
    "\n",
    "history_similarity = list()\n",
    "\n",
    "for n, m in window(ga._fitness_history):\n",
    "    features_n = set(n[0])\n",
    "    features_m = set(m[0])\n",
    "    history_similarity.append(jaccard(features_n, features_m))\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(history_similarity, marker='o', linestyle='-')\n",
    "plt.xlim(-1, )\n",
    "plt.ylim(0, 1.1)\n",
    "plt.xlabel(\"Generations\")\n",
    "plt.ylabel(\"Similarity\")\n",
    "plt.grid(True)\n",
    "plt.title(\"Jaccard similarity between the best lists of generations N and N+1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the curve is increasing, this means that the lists are getting similar. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Related works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When this algorithm was written some others works have been done but not shown in this notebook. Among these works, there is the will of parallelise the fitness function. The main idea is to run multiple MLP in parallel since the implementation of the latter in Scikit is monocore. Multiple attempts have been tried like :\n",
    "1. Using `multiprocessing` python module. The expected gain was about n times where n is the number of cores available. The reality showed that the gain was about 1.5 to 2 times faster than the sequential version. This is caused by the overhead of manipulating the objects which need to be pickled because of the [GIL](https://wiki.python.org/moin/GlobalInterpreterLock).\n",
    "2. Using `IPython.parallel` python module.\n",
    "3. Using an other library than Scikit : Keras was chosen to see if the low-level implementation with Theanos speeds up the algorithm. In practice the benefits was not so obvious.\n",
    "\n",
    "Finally the kept method is the sequential one (using the `map` build-in method) because the crossvalidation already parallelise the jobs with `n_jobs=-1` (all the tests were performed without the crossvalidation at the time).\n",
    "\n",
    "Here is a comparaison table of the performance of the implementations tried on MILE dataset, 1000 features no crossvalidation.\n",
    "\n",
    "| Python map (sequential)  – ram : 5-6 GB | Multiprocessing – ram: 9-12 GB | Iparallel – ram: 12-16 GB     | \n",
    "|-----------------------------------------|--------------------------------|-------------------------------| \n",
    "| '_create_population' 0.07 sec           | '_create_population' 0.05 sec  | '_create_population' 0.05 sec | \n",
    "| '_crossover' 0.10 sec                   | '_crossover' 0.11 sec          | '_crossover' 0.09 sec         | \n",
    "| '_mutate' 0.00 sec                      | '_mutate' 0.00 sec             | '_mutate' 0.00 sec            | \n",
    "| '_evolve' 0.10 sec                      | '_evolve' 0.11 sec             | '_evolve' 0.09 sec            | \n",
    "| '_grade_pop' 112.70 sec                 | '_grade_pop' 54.70 sec         | '_grade_pop' 51.51 sec        | \n",
    "| '_crossover' 0.12 sec                   | '_crossover' 0.13 sec          | '_crossover' 0.09 sec         | \n",
    "| '_mutate' 0.00 sec                      | '_mutate' 0.00 sec             | '_mutate' 0.00 sec            | \n",
    "| '_evolve' 0.12 sec                      | '_evolve' 0.13 sec             | '_evolve' 0.09 sec            | \n",
    "| '_grade_pop' 86.51 sec                  | '_grade_pop' 56.95 sec         | '_grade_pop' 57.31 sec        | \n",
    "| '_crossover' 0.11 sec                   | '_crossover' 0.12 sec          | '_crossover' 0.10 sec         | \n",
    "| '_mutate' 0.00 sec                      | '_mutate' 0.00 sec             | '_mutate' 0.00 sec            | \n",
    "| '_evolve' 0.11 sec                      | '_evolve' 0.12 sec             | '_evolve' 0.10 sec            | \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
