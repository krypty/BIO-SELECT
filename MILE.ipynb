{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# BIO-SELECT - Marigliano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import neighbors, datasets\n",
    "import pandas as pd\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.multiclass import OneVsOneClassifier, OneVsRestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# set float precision at 2 digits\n",
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def min_max_norm(X):\n",
    "    min_x = np.min(X)\n",
    "    return (X - min_x) / (np.max(X) - min_x)\n",
    "\n",
    "def plot_scores_per_features(scores_per_features, N=50, title=\"\"):\n",
    "    \n",
    "    fig = plt.figure(figsize=(12,6))\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    if len(scores_per_features)-1 > N:\n",
    "        features, scores = zip(*scores_per_features[:N])\n",
    "    else:\n",
    "        features, scores = zip(*scores_per_features)\n",
    "    \n",
    "    xs = range(len(scores))\n",
    "    ys = scores\n",
    "    \n",
    "    ax.bar(xs, ys, align='center', width=0.8, alpha=0.3)\n",
    "    \n",
    "    ax.set_ylabel('Score')\n",
    "    ax.set_xlabel('Features')\n",
    "    \n",
    "    ax.set_xlim(-1)    \n",
    "    \n",
    "    # add values above the bars\n",
    "    for a,b in zip(xs, ys):\n",
    "        plt.text(a, b, str(features[a]), ha='center', va='bottom', rotation=90)\n",
    "    \n",
    "    if title != \"\":\n",
    "        title = \"[\" + title + \"]\"\n",
    "    plt.title(\"%s Scores per features\" % title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from datasets.EGEOD22619.EGEOD22619Dataset import EGEOD22619Dataset\n",
    "from datasets.MILE.MileDataset import MileDataset\n",
    "from datasets.Golub99.GolubDataset import GolubDataset\n",
    "\n",
    "from datasets.DatasetEncoder import DatasetEncoder\n",
    "from datasets.DatasetSplitter import DatasetSplitter\n",
    "\n",
    "#ds = MileDataset()\n",
    "#ds = EGEOD22619Dataset()\n",
    "ds = GolubDataset()\n",
    "\n",
    "# encode Dataset string classes into numbers\n",
    "ds_encoder = DatasetEncoder(ds)\n",
    "ds = ds_encoder.encode()\n",
    "ds = DatasetSplitter(ds, test_size=0.4)\n",
    "\n",
    "X = ds.get_X()\n",
    "y = ds.get_y()\n",
    "print(len(y))\n",
    "\n",
    "X_train = ds.get_X_train()\n",
    "y_train = ds.get_y_train()\n",
    "X_test = ds.get_X_test()\n",
    "y_test = ds.get_y_test()\n",
    "\n",
    "print(len(X_train[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification using dumb KNN (all features)\n",
    "Used as reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_neighbors=4, algorithm=\"auto\")\n",
    "classifier = classifier.fit(X_train, y_train)\n",
    "\n",
    "score = classifier.score(X_test, y_test)\n",
    "print(\"score :\", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification using ExtraTrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "classifier = OneVsRestClassifier(\n",
    "    ExtraTreesClassifier(n_jobs=-1, n_estimators=100), n_jobs=-1)\n",
    "classifier = classifier.fit(X_train, y_train)\n",
    "\n",
    "print(\"Score %.3f\" % classifier.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get feature importance when using OneVs[Rest|One]Classifier\n",
    "# iterate over estimators_[i] for RF\n",
    "feat_importances = classifier.estimators_[0].feature_importances_\n",
    "feat_importances_sorted = sorted(enumerate(feat_importances), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "N = 1000\n",
    "plt.plot([feat[1] for feat in feat_importances_sorted[:N]])\n",
    "plt.xlim(-100)\n",
    "plt.title(\"Best %d features importances for ExtraTrees\" % N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_scores_per_features(feat_importances_sorted, title=\"ExtraTrees\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SelectKBest + f-classif + LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = Pipeline([('f_classif', SelectKBest(f_classif, k=1000)),\n",
    "                ('svm', OneVsRestClassifier(LinearSVC()))])\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predictions = clf.predict(X_train)\n",
    "\n",
    "score = clf.score(X_test, y_test)\n",
    "print(\"Score %.3f \" % score)\n",
    "\n",
    "s = clf.named_steps[\"f_classif\"].scores_\n",
    "print(s[:10])\n",
    "\n",
    "support = clf.named_steps['f_classif'].get_support()\n",
    "\n",
    "features = enumerate(support)\n",
    "used_features = [f[0] for f in features if f[1] == True]\n",
    "print(\"Nb used features : %d \" % len(used_features))\n",
    "print(\"5 first used features indices: %s\" % used_features[:5])\n",
    "\n",
    "# Plot scores per features\n",
    "scores_per_features = sorted(enumerate(s), key=lambda x: x[1], reverse=True)\n",
    "plot_scores_per_features(scores_per_features, title=\"SelectKBest + f_classif + LinearSVC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReliefF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skfeature.function.similarity_based import reliefF\n",
    "\n",
    "scores = reliefF.reliefF(X_train, np.array(y_train))\n",
    "\n",
    "scores_per_features = sorted(enumerate(scores), key=lambda p:p[1], reverse=True)\n",
    "\n",
    "# print the best 5 features with their score\n",
    "N = 5\n",
    "print(\"Best %d features and their ranking\" % N)\n",
    "for i in range(N):\n",
    "    print(\"\\tfeat: %d, ranking: %.2f\" % scores_per_features[i])\n",
    "\n",
    "# get best features indices\n",
    "indices = reliefF.feature_ranking(scores)\n",
    "print(indices)\n",
    "\n",
    "# Plot scores per features\n",
    "plot_scores_per_features(scores_per_features, title=\"ReliefF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fisher Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skfeature.function.similarity_based import fisher_score\n",
    "\n",
    "score = fisher_score.fisher_score(X_train, y_train)\n",
    "\n",
    "print(\"Classes: %s\" % list(set(y_train)))\n",
    "\n",
    "# print the best 5 features with their score\n",
    "n_best_features = sorted(enumerate(score), key=lambda p:p[1], reverse=True)\n",
    "print(n_best_features[:5])\n",
    "\n",
    "# get best features indices\n",
    "indices = fisher_score.feature_ranking(score)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = [f[0] for f in n_best_features]\n",
    "s = [f[1] for f in n_best_features]\n",
    "plt.plot(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_scores_per_features(n_best_features, title=\"Fisher Score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with http://featureselection.asu.edu/tutorial.php"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takes the best N features from a random subset of size M, P times\n",
    "\n",
    "with N in [1, M], M = 1000, P = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "import random\n",
    "\n",
    "acc = []\n",
    "\n",
    "max_features = 20\n",
    "\n",
    "def get_best_features_subset(features_indices):\n",
    "    max_acc = -1.0\n",
    "    \n",
    "    for N in range(1, len(features_indices)):\n",
    "        selected_features_train = X_train[:, features_indices[:N]]\n",
    "        selected_features_test = X_test[:, features_indices[:N]]\n",
    "\n",
    "        clf = svm.LinearSVC()\n",
    "\n",
    "        clf.fit(selected_features_train, y_train)\n",
    "        y_predict = clf.predict(selected_features_test)\n",
    "\n",
    "        last_acc = accuracy_score(y_test, y_predict)\n",
    "        acc.append(last_acc)\n",
    "\n",
    "        if last_acc > max_acc:\n",
    "            max_acc = last_acc\n",
    "            best_features = features_indices[:N]\n",
    "\n",
    "    return best_features, max_acc\n",
    "\n",
    "\n",
    "best_of_best_features = set()\n",
    "total_of_best_features = 0\n",
    "P = 3\n",
    "for _ in range(P):\n",
    "    random_features_indices = random.sample(range(1, len(X[0])), max_features)\n",
    "    best_features, max_acc = get_best_features_subset(random_features_indices)\n",
    "\n",
    "    print(\"max score %s with %s features\" % (max_acc, len(best_features)))\n",
    "    #print(\"Best features are %s\" % best_features)\n",
    "    print(\"\")\n",
    "    \n",
    "    best_of_best_features.update(best_features)\n",
    "    total_of_best_features += len(best_features)\n",
    "\n",
    "print(\"%s uniques features over a total of %s\" % (len(best_of_best_features), total_of_best_features))\n",
    "print(\"best of best: %s\" % best_of_best_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from skfeature.function.wrapper import svm_backward\n",
    "#\n",
    "#print(X_train)\n",
    "#print(y_train)\n",
    "#score = svm_backward.svm_backward(X_train, np.array(y_train), n_selected_features=3)\n",
    "#\n",
    "## print the best 3 features with their score\n",
    "#n_best_features = sorted(enumerate(score), key=lambda p:p[1], reverse=True)\n",
    "#print(n_best_features[:3])\n",
    "#\n",
    "## get best features indice\n",
    "#idx = svm_backward.feature_ranking(score)\n",
    "#print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from skfeature.function.statistical_based import CFS\n",
    "#\n",
    "#F = CFS.cfs(X_train, y_train)\n",
    "#print(F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [debug] Test with f_classif to understand F and pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import f_classif\n",
    "import math\n",
    "\n",
    "# basic example where only the 1st feature is important\n",
    "totoX = [[1,2], [-1,3], [-1,-2], [-1,23], [1,-2], [1,2]]\n",
    "totoY = [1, -1, -1, -1, 1, 1]\n",
    "F, pvalues = f_classif(totoX, totoY)\n",
    "\n",
    "print(F)\n",
    "print(pvalues)\n",
    "# we see that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "F, pvalues = f_classif(X, y)\n",
    "F_sorted = sorted(enumerate(F), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "N = 1000\n",
    "\n",
    "print(\"Best features according to F score: \")\n",
    "for x in F_sorted[:4]:\n",
    "    print(\"%d : %0.3f\" % (x[0], x[1]))\n",
    "\n",
    "best_X_F = F_sorted[:N]\n",
    "\n",
    "F_scores = [x[1] for x in best_X_F]\n",
    " \n",
    "plt.plot(F_scores)\n",
    "plt.ylabel('F score')\n",
    "\n",
    "plt.title('Best %s features according to F score' % N)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_scores_per_features(F_sorted, title=\"F Score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mutual Information classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "import math\n",
    "\n",
    "X_mi = mutual_info_classif(X, y, n_neighbors=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_mi_sorted = sorted(enumerate(X_mi), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "N = 1000\n",
    "\n",
    "print(\"Best features according to MI score: \")\n",
    "for x in X_mi_sorted[:4]:\n",
    "    print(\"%d : %0.3f\" % (x[0], x[1]))\n",
    "\n",
    "best_X_mi = X_mi_sorted[:N]\n",
    "\n",
    "mi_scores = [x[1] for x in best_X_mi]\n",
    " \n",
    "plt.plot(mi_scores)\n",
    "plt.ylabel('Estimated Mutual Info')\n",
    "\n",
    "plt.title('Best %s features according to mutual info' % N)\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_scores_per_features(X_mi_sorted, title=\"Mutual Info\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
